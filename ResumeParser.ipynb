{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Resume Parser**\n",
        "**Goal:** Build an intelligent parser that reads a resume and extracts structured details like contact info, skills, and job history using text extraction and pattern recognition."
      ],
      "metadata": {
        "id": "Cax5cfak0qqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Required Libraries**"
      ],
      "metadata": {
        "id": "1tmDNKhU7F51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT3vdopc0men",
        "outputId": "9365f627-bb99-4c06-861d-f27f1f1186ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.1\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy pandas pdfplumber\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Text from a Resume File (PDF or TXT)**"
      ],
      "metadata": {
        "id": "eq9xhbHP7H1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = ''\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + '\\n'\n",
        "    return text.strip()\n",
        "\n",
        "# Example usage\n",
        "resume_text = extract_text_from_pdf(\"resume.pdf\")\n",
        "print(resume_text[:500])  # Preview first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DADtYh40y9H",
        "outputId": "19385d77-c54a-4050-da0f-9679b9710074"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amr Khaled Mohamed\n",
            "+201024282025 Cairo,Egypt\n",
            "Amrkhaled.gm@gmail.com LinkedIn:\n",
            "amr-khaleddd\n",
            "GitHub:Amrok9\n",
            "⋄\n",
            "Objective\n",
            "A highly motivated and dedicated Artificial Intelligence graduate seeking a challenging job or internship\n",
            "opportunity to apply and expand my expertise in machine learning, natural language processing, computer\n",
            "vision, and reinforcement learning, Passionate about contributing to academic research and education, Eager to\n",
            "contribute toinnovativeprojects and collaborate witha dynamict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Name, Email, Phone Using Regex + SpaCy**"
      ],
      "metadata": {
        "id": "_sXZgHx_7Kf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_contact_info(text):\n",
        "    name = None\n",
        "    # Extract email using regex\n",
        "    email = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", text)\n",
        "    # Extract phone number using regex\n",
        "    phone = re.findall(r\"\\+?\\d[\\d\\s\\-]{8,15}\", text)\n",
        "\n",
        "    # Use spaCy to detect named entities\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":\n",
        "            name = ent.text\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"email\": email[0] if email else None,\n",
        "        \"phone\": phone[0] if phone else None\n",
        "    }"
      ],
      "metadata": {
        "id": "bDcHMfuw1Rmh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Skills**\n",
        "\n",
        "You can use a predefined skill set and match them against the resume text."
      ],
      "metadata": {
        "id": "8N9YQ7Jr7Mik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(text, skill_set=None):\n",
        "    if skill_set is None:\n",
        "        skill_set = {\n",
        "            \"python\", \"java\", \"sql\", \"excel\", \"aws\", \"tensorflow\",\n",
        "            \"pytorch\", \"c++\", \"javascript\", \"html\", \"css\", \"power bi\",\n",
        "            \"docker\", \"linux\", \"git\", \"machine learning\", \"deep learning\",\n",
        "            \"data analysis\", \"nlp\", \"flask\", \"django\"\n",
        "        }\n",
        "\n",
        "    found_skills = []\n",
        "    text_lower = text.lower()\n",
        "    for skill in skill_set:\n",
        "        if skill in text_lower:\n",
        "            found_skills.append(skill)\n",
        "\n",
        "    return list(set(found_skills))"
      ],
      "metadata": {
        "id": "QJqRk2Fl1bJh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Education and Experience Sections**\n",
        "\n",
        "Use keyword-based extraction."
      ],
      "metadata": {
        "id": "98Ls-WZ87T-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_section(text, keyword):\n",
        "  lines = text.lower().split('\\n')\n",
        "  section = []\n",
        "  capture = False\n",
        "  for line in lines:\n",
        "      if keyword in line:\n",
        "          capture = True\n",
        "      elif capture and line.strip() == '':\n",
        "          break\n",
        "      elif capture:\n",
        "          section.append(line.strip())\n",
        "  return ' '.join(section)"
      ],
      "metadata": {
        "id": "STSrF1_T1kja"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine All Parsers**"
      ],
      "metadata": {
        "id": "zGxpFmAa7Y5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_resume(text):\n",
        "    contact_info = extract_contact_info(text)\n",
        "    skills = extract_skills(text)\n",
        "    education = extract_section(text, \"education\")\n",
        "    experience = extract_section(text, \"experience\")\n",
        "    return {\n",
        "        **contact_info,\n",
        "        \"skills\": skills,\n",
        "        \"education\": education,\n",
        "        \"experience\": experience\n",
        "    }\n",
        "\n",
        "# Parse the resume\n",
        "parsed_data = parse_resume(resume_text)\n",
        "\n",
        "# Print extracted data\n",
        "for key, value in parsed_data.items():\n",
        "    print(f\"{key.upper()}: {value}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCvZ4fxT1otG",
        "outputId": "843c72bc-899a-4897-a5cf-01d1de3d81d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME: Amr Khaled Mohamed\n",
            "\n",
            "EMAIL: Amrkhaled.gm@gmail.com\n",
            "\n",
            "PHONE: +201024282025 \n",
            "\n",
            "SKILLS: ['pytorch', 'data analysis', 'git', 'machine learning', 'c++', 'aws', 'html', 'css', 'nlp', 'excel', 'tensorflow', 'deep learning', 'java', 'python']\n",
            "\n",
            "EDUCATION: contribute toinnovativeprojects and collaborate witha dynamicteam todriveadvancements inai technologies. professional experience instructor,digital egypt cubsinitiative july-aug, 2024  guided students in mastering key topics such as problem-solving fundamentals, creative thinking, and the software development life cycle, significantly enhancing their skills and competencies. bachelors of artificial intelligence, egyptian russian university graduation date 2024 c-gpa: 3.23 training and professional certificates alx ai career essential may, 2024 awsacademy graduate -aws academy machinelearningfoundations feb, 2024 awsacademy graduate -aws academy cloudfoundation feb, 2024 advancedlearning algorithms (coursera) dec,2023 artificial intelligence (iti - arab academy) sept, 2023 web design foundation training (aitb) may,2023 full python course (huawei ict) june, 2022 summary of skills  techinical  programming languages: python, c++, java  libraries: numpy / pandas / matplotlib/ sklearn / tensorflow/ nltk  web development: html, css  frameworks: flutter, dart, keras, tensorflow, pytorch  specialties: machine learning ,deep learning ,natural language processing (nlp), data analysis and visualization, computer vision  embedded systems: programming embedded systems  soft skills  strong analytical and critical thinking abilities  excellent communication and teamwork skills  ability to learn quickly and adapt to new technologies projects  graduation project: salam- ai-generated talkinghead avatar role: team leader |grade:a+ developed amobileapp that converts speech/textintoan ai-generated talking headavatar. collaborated with idsc andstand by ai, creating highly realisticavatars for conferences.  attendance system using face recognition captures individuals' identities and their entry time & date, while effortlessly storing the data in an excel sheet for streamlined record-keeping and management.  englishhandwritten digitrecognition developed a system forrecognizinghandwritten english digits.  smart health system a front-end website that revolutionizes the healthcare industry by seamlessly integrating innovative technologies and user-friendly interfaces to enhance patient experience and optimize medical services. it ensures efficient communication, streamlined appointments, and personalized care, making healthcare smarter, simpler, and more accessible for all.  wi-fi controlled car. using node-mcu a car that can be controlled via phone that can do some required tasks  emotion detection using face recognition developed a system that detects faces and classifies emotions, identifying whether the expression is happy, sad, angry, neutral, orscared. extra-currical activities  awarded second place inthe egyptians startupsolympics competition organized bytheinnovators support fund  participated in robotsumo2023 sponsored byeru& huawei.  workedas an organizer in astudent activity team called computability in eru.  participated in ecpc and reached thefinals  nasaspaceapps hackathon languages arabic (native) english(fluent) russian (beginner)\n",
            "\n",
            "EXPERIENCE: instructor,digital egypt cubsinitiative july-aug, 2024  guided students in mastering key topics such as problem-solving fundamentals, creative thinking, and the software development life cycle, significantly enhancing their skills and competencies. education bachelors of artificial intelligence, egyptian russian university graduation date 2024 c-gpa: 3.23 training and professional certificates alx ai career essential may, 2024 awsacademy graduate -aws academy machinelearningfoundations feb, 2024 awsacademy graduate -aws academy cloudfoundation feb, 2024 advancedlearning algorithms (coursera) dec,2023 artificial intelligence (iti - arab academy) sept, 2023 web design foundation training (aitb) may,2023 full python course (huawei ict) june, 2022 summary of skills  techinical  programming languages: python, c++, java  libraries: numpy / pandas / matplotlib/ sklearn / tensorflow/ nltk  web development: html, css  frameworks: flutter, dart, keras, tensorflow, pytorch  specialties: machine learning ,deep learning ,natural language processing (nlp), data analysis and visualization, computer vision  embedded systems: programming embedded systems  soft skills  strong analytical and critical thinking abilities  excellent communication and teamwork skills  ability to learn quickly and adapt to new technologies projects  graduation project: salam- ai-generated talkinghead avatar role: team leader |grade:a+ developed amobileapp that converts speech/textintoan ai-generated talking headavatar. collaborated with idsc andstand by ai, creating highly realisticavatars for conferences.  attendance system using face recognition captures individuals' identities and their entry time & date, while effortlessly storing the data in an excel sheet for streamlined record-keeping and management.  englishhandwritten digitrecognition developed a system forrecognizinghandwritten english digits.  smart health system a front-end website that revolutionizes the healthcare industry by seamlessly integrating medical services. it ensures efficient communication, streamlined appointments, and personalized care, making healthcare smarter, simpler, and more accessible for all.  wi-fi controlled car. using node-mcu a car that can be controlled via phone that can do some required tasks  emotion detection using face recognition developed a system that detects faces and classifies emotions, identifying whether the expression is happy, sad, angry, neutral, orscared. extra-currical activities  awarded second place inthe egyptians startupsolympics competition organized bytheinnovators support fund  participated in robotsumo2023 sponsored byeru& huawei.  workedas an organizer in astudent activity team called computability in eru.  participated in ecpc and reached thefinals  nasaspaceapps hackathon languages arabic (native) english(fluent) russian (beginner)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 **Summary**\n",
        "\n",
        "This project extracts structured information from resume PDFs using NLP and regex.\n",
        "\n",
        "**Main Features Extracted:**\n",
        "- 👤 Name (using spaCy's NER model)\n",
        "- 📧 Email (regex)\n",
        "- 📱 Phone number (regex)\n",
        "- 🧠 Skills (matched from a predefined skill set)\n",
        "- 🎓 Education section (keyword-based)\n",
        "- 💼 Experience section (keyword-based)\n",
        "\n",
        "**Libraries Used:**\n",
        "- `pdfplumber`: To extract text from PDF\n",
        "- `spaCy`: For name entity recognition (PERSON)\n",
        "- `re`: For pattern matching (email, phone)\n",
        "- `set()`: For matching known skills\n",
        "\n",
        "**Steps:**\n",
        "1. Read text from resume PDF\n",
        "2. Extract contact info (name, email, phone)\n",
        "3. Match known skills in the text\n",
        "4. Extract sections like Education & Experience using keyword heuristics\n",
        "\n",
        "✅ This project demonstrates how to build a basic resume parser using rule-based and NLP techniques, which can be enhanced further for real-world applications.\n"
      ],
      "metadata": {
        "id": "ylrY_OhG68x2"
      }
    }
  ]
}